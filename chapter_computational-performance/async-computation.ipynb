{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "af385def",
      "metadata": {
        "id": "af385def"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "46b7b7fc",
      "metadata": {
        "id": "46b7b7fc",
        "outputId": "11c8a13d-d10b-4da1-fefc-71ce686809f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting d2l==1.0.0-alpha1.post0\n",
            "  Downloading d2l-1.0.0a1.post0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 972 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (1.3.5)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (2.23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (3.2.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->d2l==1.0.0-alpha1.post0) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym->d2l==1.0.0-alpha1.post0) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym->d2l==1.0.0-alpha1.post0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->d2l==1.0.0-alpha1.post0) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->d2l==1.0.0-alpha1.post0) (4.1.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (7.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.3.4)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.5.0)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.3.2-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (7.9.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (6.1.12)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (1.15.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (3.0.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (3.6.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (0.2.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (23.2.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (5.7.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (4.11.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (0.11.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (5.0.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.16.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (5.10.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==1.0.0-alpha1.post0) (2022.4)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.2.1-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 799 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy>=2.0.1->qtconsole->jupyter->d2l==1.0.0-alpha1.post0) (21.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (3.0.4)\n",
            "Installing collected packages: jedi, qtpy, qtconsole, matplotlib-inline, jupyter, d2l\n",
            "Successfully installed d2l-1.0.0a1.post0 jedi-0.18.1 jupyter-1.0.0 matplotlib-inline-0.1.6 qtconsole-5.3.2 qtpy-2.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e1b557e",
      "metadata": {
        "origin_pos": 0,
        "id": "5e1b557e"
      },
      "source": [
        "# Asynchronous Computation\n",
        ":label:`sec_async`\n",
        "\n",
        "Today's computers are highly parallel systems, consisting of multiple CPU cores (often multiple threads per core), multiple processing elements per GPU, and often multiple GPUs per device. In short, we can process many different things at the same time, often on different devices. Unfortunately Python is not a great way of writing parallel and asynchronous code, at least not without some extra help. After all, Python is single-threaded and this is unlikely to change in the future. Deep learning frameworks such as MXNet and TensorFlow adopt an *asynchronous programming* model to improve performance,\n",
        "while PyTorch uses Python's own scheduler leading to a different performance trade-off.\n",
        "For PyTorch, by default, GPU operations are asynchronous. When you call a function that uses the GPU, the operations are enqueued to the particular device, but not necessarily executed until later. This allows us to execute more computations in parallel, including operations on the CPU or other GPUs.\n",
        "\n",
        "Hence, understanding how asynchronous programming works helps us to develop more efficient programs, by proactively reducing computational requirements and mutual dependencies. This allows us to reduce memory overhead and increase processor utilization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e1273e0d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:20:06.599934Z",
          "iopub.status.busy": "2022-09-07T22:20:06.599215Z",
          "iopub.status.idle": "2022-09-07T22:20:08.472020Z",
          "shell.execute_reply": "2022-09-07T22:20:08.471185Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "e1273e0d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import numpy\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b52e4465",
      "metadata": {
        "origin_pos": 3,
        "id": "b52e4465"
      },
      "source": [
        "## Asynchrony via Backend\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a96c6b7d",
      "metadata": {
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "a96c6b7d"
      },
      "source": [
        "For a warmup consider the following toy problem: we want to generate a random matrix and multiply it. Let's do that both in NumPy and in PyTorch tensor to see the difference.\n",
        "Note that PyTorch `tensor` is defined on a GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5eb48036",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:20:08.478456Z",
          "iopub.status.busy": "2022-09-07T22:20:08.478067Z",
          "iopub.status.idle": "2022-09-07T22:20:12.928844Z",
          "shell.execute_reply": "2022-09-07T22:20:12.927456Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "5eb48036",
        "outputId": "d996ea1f-925d-48ff-b5f7-95471e490051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy: 0.9145 sec\n",
            "torch: 0.0010 sec\n"
          ]
        }
      ],
      "source": [
        "# Warmup for GPU computation\n",
        "device = d2l.try_gpu()\n",
        "a = torch.randn(size=(1000, 1000), device=device)\n",
        "b = torch.mm(a, a)\n",
        "\n",
        "with d2l.Benchmark('numpy'):\n",
        "    for _ in range(10):\n",
        "        a = numpy.random.normal(size=(1000, 1000))\n",
        "        b = numpy.dot(a, a)\n",
        "\n",
        "with d2l.Benchmark('torch'):\n",
        "    for _ in range(10):\n",
        "        a = torch.randn(size=(1000, 1000), device=device)\n",
        "        b = torch.mm(a, a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93af9f05",
      "metadata": {
        "origin_pos": 9,
        "tab": [
          "pytorch"
        ],
        "id": "93af9f05"
      },
      "source": [
        "The benchmark output via PyTorch is orders of magnitude faster.\n",
        "NumPy dot product is executed on the CPU processor while\n",
        "PyTorch matrix multiplication is executed on GPU and hence the latter\n",
        "is expected to be much faster. But the huge time difference suggests something\n",
        "else must be going on.\n",
        "By default, GPU operations are asynchronous in PyTorch.\n",
        "Forcing PyTorch to finish all computation prior to returning shows\n",
        "what happened previously: computation is being executed by the backend\n",
        "while the frontend returns control to Python.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "89aa0c61",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:20:12.935489Z",
          "iopub.status.busy": "2022-09-07T22:20:12.934169Z",
          "iopub.status.idle": "2022-09-07T22:20:12.945847Z",
          "shell.execute_reply": "2022-09-07T22:20:12.944533Z"
        },
        "origin_pos": 11,
        "tab": [
          "pytorch"
        ],
        "id": "89aa0c61",
        "outputId": "def4f116-a5aa-4396-a90a-c074f77b5e76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done: 0.0086 sec\n"
          ]
        }
      ],
      "source": [
        "with d2l.Benchmark():\n",
        "    for _ in range(10):\n",
        "        a = torch.randn(size=(1000, 1000), device=device)\n",
        "        b = torch.mm(a, a)\n",
        "    torch.cuda.synchronize(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ce0d38",
      "metadata": {
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "id": "96ce0d38"
      },
      "source": [
        "Broadly speaking, PyTorch has a frontend for direct interaction with the users, e.g., via Python, as well as a backend used by the system to perform the computation. \n",
        "As shown in :numref:`fig_frontends`, users can write PyTorch programs in various frontend languages, such as Python and C++. Regardless of the frontend programming language used, the execution of PyTorch programs occurs primarily in the backend of C++ implementations. Operations issued by the frontend language are passed on to the backend for execution.\n",
        "The backend manages its own threads that continuously collect and execute queued tasks.\n",
        "Note that for this to work the backend must be able to keep track of the\n",
        "dependencies between various steps in the computational graph.\n",
        "Hence, it is not possible to parallelize operations that depend on each other.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "296567fd",
      "metadata": {
        "origin_pos": 14,
        "id": "296567fd"
      },
      "source": [
        "![Programming language frontends and deep learning framework backends.](https://github.com/d2l-ai/d2l-pytorch-colab/blob/master/img/frontends.png?raw=1)\n",
        ":width:`300px`\n",
        ":label:`fig_frontends`\n",
        "\n",
        "Let's look at another toy example to understand the dependency graph a bit better.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f35ddfc8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:20:12.951837Z",
          "iopub.status.busy": "2022-09-07T22:20:12.951093Z",
          "iopub.status.idle": "2022-09-07T22:20:12.979557Z",
          "shell.execute_reply": "2022-09-07T22:20:12.978155Z"
        },
        "origin_pos": 16,
        "tab": [
          "pytorch"
        ],
        "id": "f35ddfc8",
        "outputId": "5971cfdc-db65-48be-fc1e-c5c7cb71995a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x = torch.ones((1, 2), device=device)\n",
        "y = torch.ones((1, 2), device=device)\n",
        "z = x * y + 2\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9285203a",
      "metadata": {
        "origin_pos": 17,
        "id": "9285203a"
      },
      "source": [
        "![The backend tracks dependencies between various steps in the computational graph.](http://d2l.ai/_images/asyncgraph.svg)\n",
        ":label:`fig_asyncgraph`\n",
        "\n",
        "\n",
        "\n",
        "The code snippet above is also illustrated in :numref:`fig_asyncgraph`.\n",
        "Whenever the Python frontend thread executes one of the first three statements, it simply returns the task to the backend queue. When the last statement's results need to be *printed*, the Python frontend thread will wait for the C++ backend thread to finish computing the result of the variable `z`. One benefit of this design is that the Python frontend thread does not need to perform actual computations. Thus, there is little impact on the program's overall performance, regardless of Python's performance. :numref:`fig_threading` illustrates how frontend and backend interact.\n",
        "\n",
        "![Interactions of the frontend and backend.](http://d2l.ai/_images/threading.svg)\n",
        ":label:`fig_threading`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Barriers and Blockers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f623b1d",
      "metadata": {
        "origin_pos": 22,
        "id": "5f623b1d"
      },
      "source": [
        "## Improving Computation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f654f45",
      "metadata": {
        "origin_pos": 26,
        "id": "3f654f45"
      },
      "source": [
        "## Summary\n",
        "\n",
        "\n",
        "* Deep learning frameworks may decouple the Python frontend from an execution backend. This allows for fast asynchronous insertion of commands into the backend and associated parallelism.\n",
        "* Asynchrony leads to a rather responsive frontend. However, use caution not to overfill the task queue since it may lead to excessive memory consumption. It is recommended to synchronize for each minibatch to keep frontend and backend approximately synchronized.\n",
        "* Chip vendors offer sophisticated performance analysis tools to obtain a much more fine-grained insight into the efficiency of deep learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bfeb340",
      "metadata": {
        "origin_pos": 28,
        "id": "6bfeb340"
      },
      "source": [
        "## Exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b41a251d",
      "metadata": {
        "origin_pos": 30,
        "tab": [
          "pytorch"
        ],
        "id": "b41a251d"
      },
      "source": [
        "1. On the CPU, benchmark the same matrix multiplication operations in this section. Can you still observe asynchrony via the backend?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e70f9d6",
      "metadata": {
        "origin_pos": 32,
        "tab": [
          "pytorch"
        ],
        "id": "5e70f9d6"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/2564)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}