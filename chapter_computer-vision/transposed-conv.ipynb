{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe8b92ec",
      "metadata": {
        "id": "fe8b92ec"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c886967d",
      "metadata": {
        "id": "c886967d",
        "outputId": "f47cb341-1ea5-4793-da30-a6db4fe56dc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting d2l==1.0.0-alpha1.post0\n",
            "  Downloading d2l-1.0.0a1.post0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.0 MB/s \n",
            "\u001b[?25hCollecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (1.21.6)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (0.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (2.23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l==1.0.0-alpha1.post0) (3.2.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym->d2l==1.0.0-alpha1.post0) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->d2l==1.0.0-alpha1.post0) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym->d2l==1.0.0-alpha1.post0) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->d2l==1.0.0-alpha1.post0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->d2l==1.0.0-alpha1.post0) (3.9.0)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.3.2-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (6.1.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.5.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.3.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (7.7.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.6.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (5.1.1)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (7.9.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 61.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.7.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (1.15.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (3.6.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (3.0.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (4.11.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (1.8.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (5.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (1.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (5.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.4)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.16.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.18.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==1.0.0-alpha1.post0) (2022.4)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.2.1-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 988 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy>=2.0.1->qtconsole->jupyter->d2l==1.0.0-alpha1.post0) (21.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (2.10)\n",
            "Installing collected packages: jedi, qtpy, qtconsole, matplotlib-inline, jupyter, d2l\n",
            "Successfully installed d2l-1.0.0a1.post0 jedi-0.18.1 jupyter-1.0.0 matplotlib-inline-0.1.6 qtconsole-5.3.2 qtpy-2.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d5f336",
      "metadata": {
        "origin_pos": 0,
        "id": "46d5f336"
      },
      "source": [
        "# Transposed Convolution\n",
        ":label:`sec_transposed_conv`\n",
        "\n",
        "The CNN layers we have seen so far,\n",
        "such as convolutional layers (:numref:`sec_conv_layer`) and pooling layers (:numref:`sec_pooling`),\n",
        "typically reduce (downsample) the spatial dimensions (height and width) of the input,\n",
        "or keep them unchanged.\n",
        "In semantic segmentation\n",
        "that classifies at pixel-level,\n",
        "it will be convenient if\n",
        "the spatial dimensions of the\n",
        "input and output are the same.\n",
        "For example,\n",
        "the channel dimension at one output pixel \n",
        "can hold the classification results\n",
        "for the input pixel at the same spatial position.\n",
        "\n",
        "\n",
        "To achieve this, especially after \n",
        "the spatial dimensions are reduced by CNN layers,\n",
        "we can use another type\n",
        "of CNN layers\n",
        "that can increase (upsample) the spatial dimensions\n",
        "of intermediate feature maps.\n",
        "In this section,\n",
        "we will introduce \n",
        "*transposed convolution*, which is also called *fractionally-strided convolution* :cite:`Dumoulin.Visin.2016`, \n",
        "for reversing downsampling operations\n",
        "by the convolution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e2c43d67",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:39.798479Z",
          "iopub.status.busy": "2022-09-07T22:07:39.797752Z",
          "iopub.status.idle": "2022-09-07T22:07:41.828384Z",
          "shell.execute_reply": "2022-09-07T22:07:41.827493Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "e2c43d67"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e89e64",
      "metadata": {
        "origin_pos": 3,
        "id": "08e89e64"
      },
      "source": [
        "## Basic Operation\n",
        "\n",
        "Ignoring channels for now,\n",
        "let's begin with\n",
        "the basic transposed convolution operation\n",
        "with stride of 1 and no padding.\n",
        "Suppose that\n",
        "we are given a \n",
        "$n_h \\times n_w$ input tensor\n",
        "and a $k_h \\times k_w$ kernel.\n",
        "Sliding the kernel window with stride of 1\n",
        "for $n_w$ times in each row\n",
        "and $n_h$ times in each column\n",
        "yields \n",
        "a total of $n_h n_w$ intermediate results.\n",
        "Each intermediate result is\n",
        "a $(n_h + k_h - 1) \\times (n_w + k_w - 1)$\n",
        "tensor that are initialized as zeros.\n",
        "To compute each intermediate tensor,\n",
        "each element in the input tensor\n",
        "is multiplied by the kernel\n",
        "so that the resulting $k_h \\times k_w$ tensor\n",
        "replaces a portion in\n",
        "each intermediate tensor.\n",
        "Note that\n",
        "the position of the replaced portion in each\n",
        "intermediate tensor corresponds to the position of the element\n",
        "in the input tensor used for the computation.\n",
        "In the end, all the intermediate results\n",
        "are summed over to produce the output.\n",
        "\n",
        "As an example,\n",
        ":numref:`fig_trans_conv` illustrates\n",
        "how transposed convolution with a $2\\times 2$ kernel is computed for a $2\\times 2$ input tensor.\n",
        "\n",
        "\n",
        "![Transposed convolution with a $2\\times 2$ kernel. The shaded portions are a portion of an intermediate tensor as well as the input and kernel tensor elements used for the  computation.](http://d2l.ai/_images/trans_conv.svg)\n",
        ":label:`fig_trans_conv`\n",
        "\n",
        "\n",
        "We can (**implement this basic transposed convolution operation**) `trans_conv` for a input matrix `X` and a kernel matrix `K`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0282df7d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.833502Z",
          "iopub.status.busy": "2022-09-07T22:07:41.832921Z",
          "iopub.status.idle": "2022-09-07T22:07:41.838328Z",
          "shell.execute_reply": "2022-09-07T22:07:41.837560Z"
        },
        "origin_pos": 4,
        "tab": [
          "pytorch"
        ],
        "id": "0282df7d"
      },
      "outputs": [],
      "source": [
        "def trans_conv(X, K):\n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] + h - 1, X.shape[1] + w - 1))\n",
        "    for i in range(X.shape[0]):\n",
        "        for j in range(X.shape[1]):\n",
        "            Y[i: i + h, j: j + w] += X[i, j] * K\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81988d50",
      "metadata": {
        "origin_pos": 5,
        "id": "81988d50"
      },
      "source": [
        "In contrast to the regular convolution (in :numref:`sec_conv_layer`) that *reduces* input elements\n",
        "via the kernel,\n",
        "the transposed convolution\n",
        "*broadcasts* input elements \n",
        "via the kernel, thereby\n",
        "producing an output\n",
        "that is larger than the input.\n",
        "We can construct the input tensor `X` and the kernel tensor `K` from :numref:`fig_trans_conv` to [**validate the output of the above implementation**] of the basic two-dimensional transposed convolution operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a334c36f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.841762Z",
          "iopub.status.busy": "2022-09-07T22:07:41.841317Z",
          "iopub.status.idle": "2022-09-07T22:07:41.871067Z",
          "shell.execute_reply": "2022-09-07T22:07:41.870134Z"
        },
        "origin_pos": 6,
        "tab": [
          "pytorch"
        ],
        "id": "a334c36f",
        "outputId": "28bc89e0-1f5d-4cec-c051-9e7a2eb46bc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  0.,  1.],\n",
              "        [ 0.,  4.,  6.],\n",
              "        [ 4., 12.,  9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "trans_conv(X, K)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53f0a122",
      "metadata": {
        "origin_pos": 7,
        "id": "53f0a122"
      },
      "source": [
        "Alternatively,\n",
        "when the input `X` and kernel `K` are both\n",
        "four-dimensional tensors,\n",
        "we can [**use high-level APIs to obtain the same results**].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5462bcbc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.875638Z",
          "iopub.status.busy": "2022-09-07T22:07:41.875039Z",
          "iopub.status.idle": "2022-09-07T22:07:41.885123Z",
          "shell.execute_reply": "2022-09-07T22:07:41.884146Z"
        },
        "origin_pos": 9,
        "tab": [
          "pytorch"
        ],
        "id": "5462bcbc",
        "outputId": "43751921-396e-4806-b03c-6e2986195dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  0.,  1.],\n",
              "          [ 0.,  4.,  6.],\n",
              "          [ 4., 12.,  9.]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2)\n",
        "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False)\n",
        "tconv.weight.data = K\n",
        "tconv(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a573ea22",
      "metadata": {
        "origin_pos": 10,
        "id": "a573ea22"
      },
      "source": [
        "## [**Padding, Strides, and Multiple Channels**]\n",
        "\n",
        "Different from in the regular convolution\n",
        "where padding is applied to input,\n",
        "it is applied to output\n",
        "in the transposed convolution.\n",
        "For example,\n",
        "when specifying the padding number\n",
        "on either side of the height and width \n",
        "as 1,\n",
        "the first and last rows and columns\n",
        "will be removed from the transposed convolution output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7a4aef6b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.888840Z",
          "iopub.status.busy": "2022-09-07T22:07:41.888255Z",
          "iopub.status.idle": "2022-09-07T22:07:41.896493Z",
          "shell.execute_reply": "2022-09-07T22:07:41.895600Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "7a4aef6b",
        "outputId": "f6a76827-9f32-46a1-b413-32efad7a892c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[4.]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, padding=1, bias=False)\n",
        "tconv.weight.data = K\n",
        "tconv(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f561f9b",
      "metadata": {
        "origin_pos": 13,
        "id": "5f561f9b"
      },
      "source": [
        "In the transposed convolution,\n",
        "strides are specified for intermediate results (thus output), not for input.\n",
        "Using the same input and kernel tensors\n",
        "from :numref:`fig_trans_conv`,\n",
        "changing the stride from 1 to 2\n",
        "increases both the height and weight\n",
        "of intermediate tensors, hence the output tensor\n",
        "in :numref:`fig_trans_conv_stride2`.\n",
        "\n",
        "\n",
        "![Transposed convolution with a $2\\times 2$ kernel with stride of 2. The shaded portions are a portion of an intermediate tensor as well as the input and kernel tensor elements used for the  computation.](http://d2l.ai/_images/trans_conv_stride2.svg)\n",
        ":label:`fig_trans_conv_stride2`\n",
        "\n",
        "\n",
        "\n",
        "The following code snippet can validate the transposed convolution output for stride of 2 in :numref:`fig_trans_conv_stride2`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f3d8eb1e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.899984Z",
          "iopub.status.busy": "2022-09-07T22:07:41.899477Z",
          "iopub.status.idle": "2022-09-07T22:07:41.907284Z",
          "shell.execute_reply": "2022-09-07T22:07:41.906501Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "id": "f3d8eb1e",
        "outputId": "22b4a83d-73db-4687-e9d0-3e5aa9af176c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 0., 1.],\n",
              "          [0., 0., 2., 3.],\n",
              "          [0., 2., 0., 3.],\n",
              "          [4., 6., 6., 9.]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, stride=2, bias=False)\n",
        "tconv.weight.data = K\n",
        "tconv(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f30f0be4",
      "metadata": {
        "origin_pos": 16,
        "id": "f30f0be4"
      },
      "source": [
        "For multiple input and output channels,\n",
        "the transposed convolution\n",
        "works in the same way as the regular convolution.\n",
        "Suppose that\n",
        "the input has $c_i$ channels,\n",
        "and that the transposed convolution\n",
        "assigns a $k_h\\times k_w$ kernel tensor\n",
        "to each input channel.\n",
        "When multiple output channels \n",
        "are specified,\n",
        "we will have a $c_i\\times k_h\\times k_w$ kernel for each output channel.\n",
        "\n",
        "\n",
        "As in all, if we feed $\\mathsf{X}$ into a convolutional layer $f$ to output $\\mathsf{Y}=f(\\mathsf{X})$ and create a transposed convolutional layer $g$ with the same hyperparameters as $f$ except \n",
        "for the number of output channels \n",
        "being the number of channels in $\\mathsf{X}$,\n",
        "then $g(Y)$ will have the same shape as $\\mathsf{X}$.\n",
        "This can be illustrated in the following example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "34161773",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.911589Z",
          "iopub.status.busy": "2022-09-07T22:07:41.910731Z",
          "iopub.status.idle": "2022-09-07T22:07:41.923307Z",
          "shell.execute_reply": "2022-09-07T22:07:41.922379Z"
        },
        "origin_pos": 18,
        "tab": [
          "pytorch"
        ],
        "id": "34161773",
        "outputId": "20069883-905b-4aeb-ca44-af186327b102",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "X = torch.rand(size=(1, 10, 16, 16))\n",
        "conv = nn.Conv2d(10, 20, kernel_size=5, padding=2, stride=3)\n",
        "tconv = nn.ConvTranspose2d(20, 10, kernel_size=5, padding=2, stride=3)\n",
        "tconv(conv(X)).shape == X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f580852",
      "metadata": {
        "origin_pos": 19,
        "id": "3f580852"
      },
      "source": [
        "## [**Connection to Matrix Transposition**]\n",
        ":label:`subsec-connection-to-mat-transposition`\n",
        "\n",
        "The transposed convolution is named after\n",
        "the matrix transposition.\n",
        "To explain,\n",
        "let's first\n",
        "see how to implement convolutions\n",
        "using matrix multiplications.\n",
        "In the example below, we define a $3\\times 3$ input `X` and a $2\\times 2$ convolution kernel `K`, and then use the `corr2d` function to compute the convolution output `Y`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "99cffe3c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.927119Z",
          "iopub.status.busy": "2022-09-07T22:07:41.926446Z",
          "iopub.status.idle": "2022-09-07T22:07:41.934210Z",
          "shell.execute_reply": "2022-09-07T22:07:41.933386Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "id": "99cffe3c",
        "outputId": "45868f64-24c7-4aef-9ecb-834949dead28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[27., 37.],\n",
              "        [57., 67.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X = torch.arange(9.0).reshape(3, 3)\n",
        "K = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "Y = d2l.corr2d(X, K)\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "473b7f98",
      "metadata": {
        "origin_pos": 21,
        "id": "473b7f98"
      },
      "source": [
        "Next, we rewrite the convolution kernel `K` as\n",
        "a sparse weight matrix `W`\n",
        "containing a lot of zeros. \n",
        "The shape of the weight matrix is ($4$, $9$),\n",
        "where the non-zero elements come from\n",
        "the convolution kernel `K`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ea961b51",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.937649Z",
          "iopub.status.busy": "2022-09-07T22:07:41.937365Z",
          "iopub.status.idle": "2022-09-07T22:07:41.946054Z",
          "shell.execute_reply": "2022-09-07T22:07:41.945181Z"
        },
        "origin_pos": 22,
        "tab": [
          "pytorch"
        ],
        "id": "ea961b51",
        "outputId": "c30fff61-602c-4396-f096-dc7bc353c29f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 0., 3., 4., 0., 0., 0., 0.],\n",
              "        [0., 1., 2., 0., 3., 4., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 2., 0., 3., 4., 0.],\n",
              "        [0., 0., 0., 0., 1., 2., 0., 3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "def kernel2matrix(K):\n",
        "    k, W = torch.zeros(5), torch.zeros((4, 9))\n",
        "    k[:2], k[3:5] = K[0, :], K[1, :]\n",
        "    W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k\n",
        "    return W\n",
        "\n",
        "W = kernel2matrix(K)\n",
        "W"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2553c791",
      "metadata": {
        "origin_pos": 23,
        "id": "2553c791"
      },
      "source": [
        "Concatenate the input `X` row by row to get a vector of length 9. Then the matrix multiplication of `W` and the vectorized `X` gives a vector of length 4.\n",
        "After reshaping it, we can obtain the same result `Y`\n",
        "from the original convolution operation above:\n",
        "we just implemented convolutions using matrix multiplications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9bac7150",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.949506Z",
          "iopub.status.busy": "2022-09-07T22:07:41.949219Z",
          "iopub.status.idle": "2022-09-07T22:07:41.956192Z",
          "shell.execute_reply": "2022-09-07T22:07:41.955366Z"
        },
        "origin_pos": 24,
        "tab": [
          "pytorch"
        ],
        "id": "9bac7150",
        "outputId": "b89d07be-a94a-4235-e589-67668bb1755c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True],\n",
              "        [True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "Y == torch.matmul(W, X.reshape(-1)).reshape(2, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642e35be",
      "metadata": {
        "origin_pos": 25,
        "id": "642e35be"
      },
      "source": [
        "Likewise, we can implement transposed convolutions using\n",
        "matrix multiplications.\n",
        "In the following example,\n",
        "we take the $2 \\times 2$ output `Y` from the above\n",
        "regular convolution\n",
        "as input to the transposed convolution.\n",
        "To implement this operation by multiplying matrices,\n",
        "we only need to transpose the weight matrix `W`\n",
        "with the new shape $(9, 4)$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3114e5d1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:07:41.959524Z",
          "iopub.status.busy": "2022-09-07T22:07:41.959236Z",
          "iopub.status.idle": "2022-09-07T22:07:41.966081Z",
          "shell.execute_reply": "2022-09-07T22:07:41.965255Z"
        },
        "origin_pos": 26,
        "tab": [
          "pytorch"
        ],
        "id": "3114e5d1",
        "outputId": "898eb6c4-7f53-43af-9fb0-52681ff45530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "Z = trans_conv(Y, K)\n",
        "Z == torch.matmul(W.T, Y.reshape(-1)).reshape(3, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70014991",
      "metadata": {
        "origin_pos": 27,
        "id": "70014991"
      },
      "source": [
        "Consider implementing the convolution\n",
        "by multiplying matrices.\n",
        "Given an input vector $\\mathbf{x}$\n",
        "and a weight matrix $\\mathbf{W}$,\n",
        "the forward propagation function of the convolution\n",
        "can be implemented\n",
        "by multiplying its input with the weight matrix\n",
        "and outputting a vector \n",
        "$\\mathbf{y}=\\mathbf{W}\\mathbf{x}$.\n",
        "Since backpropagation\n",
        "follows the chain rule\n",
        "and $\\nabla_{\\mathbf{x}}\\mathbf{y}=\\mathbf{W}^\\top$,\n",
        "the backpropagation function of the convolution\n",
        "can be implemented\n",
        "by multiplying its input with the \n",
        "transposed weight matrix $\\mathbf{W}^\\top$.\n",
        "Therefore, \n",
        "the transposed convolutional layer\n",
        "can just exchange the forward propagation function\n",
        "and the backpropagation function of the convolutional layer:\n",
        "its forward propagation \n",
        "and backpropagation functions\n",
        "multiply their input vector with \n",
        "$\\mathbf{W}^\\top$ and $\\mathbf{W}$, respectively.\n",
        "\n",
        "\n",
        "## Summary\n",
        "\n",
        "* In contrast to the regular convolution that reduces input elements via the kernel, the transposed convolution broadcasts input elements via the kernel, thereby producing an output that is larger than the input.\n",
        "* If we feed $\\mathsf{X}$ into a convolutional layer $f$ to output $\\mathsf{Y}=f(\\mathsf{X})$ and create a transposed convolutional layer $g$ with the same hyperparameters as $f$ except for the number of output channels being the number of channels in $\\mathsf{X}$, then $g(Y)$ will have the same shape as $\\mathsf{X}$.\n",
        "* We can implement convolutions using matrix multiplications. The transposed convolutional layer can just exchange the forward propagation function and the backpropagation function of the convolutional layer.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. In :numref:`subsec-connection-to-mat-transposition`, the convolution input `X` and the transposed convolution output `Z` have the same shape. Do they have the same value? Why?\n",
        "1. Is it efficient to use matrix multiplications to implement convolutions? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecb79f70",
      "metadata": {
        "origin_pos": 29,
        "tab": [
          "pytorch"
        ],
        "id": "ecb79f70"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/1450)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}